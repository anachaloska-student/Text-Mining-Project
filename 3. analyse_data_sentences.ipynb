{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SENTENCE - BASED ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "from __future__ import division   # Only for Python 2.7, comment out if you're using Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Files and inputs\n",
    "CATEGORIES_FILE = 'categories.json'\n",
    "DATA_FILE = 'output_data_sentences.csv'\n",
    "ANALYSIS_FILE = 'analysis_output_sentences.json'\n",
    "OUTPUT_FILE = 'topics.json'\n",
    "WORD_BUFFER_SIZE = 400\n",
    "WORD_OFFSET = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMOTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Assignes a numerical value for the *EMOTIONS* of each *sentence* in each review.**\n",
    "- **Creates a .json file with these values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init\n",
    "categories = {}\n",
    "input_data = []\n",
    "max_values = {}\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read categories\n",
    "with open(CATEGORIES_FILE) as f:\n",
    "    categories = json.load(f)\n",
    "    emotions = categories['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "color\n",
      "orientation\n",
      "sentiment\n",
      "subjectivity\n"
     ]
    }
   ],
   "source": [
    "# Init max\n",
    "for c in categories:\n",
    "    print(c)\n",
    "    max_values[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data file\n",
    "# elımınates some sentences (empty rows)\n",
    "input_data = []\n",
    "with open(DATA_FILE, 'r') as f:\n",
    "    all_rows = csv.reader(f, delimiter=',')\n",
    "    headers = next(all_rows, None) # remove header\n",
    "    rows = []\n",
    "    for row in all_rows:\n",
    "        if row != []:\n",
    "            rows.append(row)\n",
    "        else:\n",
    "            continue\n",
    "    for row in rows:\n",
    "        entry = {}\n",
    "        for i, h in enumerate(headers):\n",
    "            if len(row[i])>1:\n",
    "                entry[h] = row[i]\n",
    "            else:\n",
    "                entry[h] = int(row[i])\n",
    "        input_data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of lists of dictionaries(word + emotions + review number) of each review \n",
    "list_of_reviews = []\n",
    "\n",
    "amount_reviews = set()\n",
    "for row in input_data:\n",
    "    i = int(row['review'])\n",
    "    amount_reviews.add(i)\n",
    "\n",
    "for i in range(len(amount_reviews)):\n",
    "    review = []\n",
    "    for row in input_data:\n",
    "        if int(row['review']) == i:\n",
    "            review.append(row)\n",
    "    list_of_reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_sentences_per_review = []\n",
    "for review in list_of_reviews:\n",
    "    amount_sentences = set()\n",
    "    for row in review:\n",
    "        i = int(row['sentence'])\n",
    "        amount_sentences.add(i)\n",
    "    amount_sentences_per_review.append(max(amount_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lol_of_reviews = [] # List of lists of reviews\n",
    "\n",
    "for i, rev in enumerate(list_of_reviews):\n",
    "    review = []\n",
    "    for j in range(amount_sentences_per_review[i]):\n",
    "        sentence = []\n",
    "        for word in rev:\n",
    "            if int(word['review']) == i and int(word['sentence']) == j:\n",
    "                sentence.append(word)\n",
    "        review.append(sentence)\n",
    "    lol_of_reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewlist = []\n",
    "\n",
    "for review in lol_of_reviews:\n",
    "    sentences = []\n",
    "    for i, sentence in enumerate(review):\n",
    "        if len(sentence) != 0:\n",
    "            sentences.append(sentence)\n",
    "        else:\n",
    "            continue\n",
    "    reviewlist.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_all_reviews = []\n",
    "\n",
    "for review in reviewlist:\n",
    "    anger_score = []\n",
    "    fear_score = []\n",
    "    anticipation_score = []\n",
    "    trust_score = []\n",
    "    surprise_score = []\n",
    "    sadness_score = []\n",
    "    joy_score = []\n",
    "    disgust_score = []\n",
    "    scores = []\n",
    "    for sentence in review:\n",
    "        amount_of_words = len(sentence)\n",
    "        anger = []\n",
    "        fear = []\n",
    "        anticipation = []\n",
    "        trust = []\n",
    "        surprise = []\n",
    "        sadness = []\n",
    "        joy = []\n",
    "        disgust = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            anger.append(sentence[i]['anger'])\n",
    "            fear.append(sentence[i]['fear'])\n",
    "            anticipation.append(sentence[i]['anticipation'])\n",
    "            trust.append(sentence[i]['trust'])\n",
    "            surprise.append(sentence[i]['surprise'])\n",
    "            sadness.append(sentence[i]['sadness'])\n",
    "            joy.append(sentence[i]['joy'])\n",
    "            disgust.append(sentence[i]['disgust'])\n",
    "\n",
    "        anger_score.append(sum(anger)/amount_of_words)\n",
    "        fear_score.append(sum(fear)/amount_of_words)\n",
    "        anticipation_score.append(sum(anticipation)/amount_of_words)\n",
    "        trust_score.append(sum(trust)/amount_of_words)\n",
    "        surprise_score.append(sum(surprise)/amount_of_words)\n",
    "        sadness_score.append(sum(sadness)/amount_of_words)\n",
    "        joy_score.append(sum(joy)/amount_of_words)\n",
    "        disgust_score.append(sum(disgust)/amount_of_words)\n",
    "\n",
    "    scores.append(anger_score)\n",
    "    scores.append(fear_score)\n",
    "    scores.append(anticipation_score)\n",
    "    scores.append(trust_score)\n",
    "    scores.append(surprise_score)\n",
    "    scores.append(sadness_score)\n",
    "    scores.append(joy_score)\n",
    "    scores.append(disgust_score)\n",
    "    \n",
    "    scores_all_reviews.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_transposed = []\n",
    "\n",
    "for review in scores_all_reviews:\n",
    "    scores_transposed.append(np.transpose(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_total = []\n",
    "\n",
    "for review in scores_transposed:\n",
    "    for sentence in review:\n",
    "        scores_total.append(list(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 18185 entries to file: analysis_output_sentences.json\n"
     ]
    }
   ],
   "source": [
    "with open(ANALYSIS_FILE, 'w') as f:\n",
    "    json.dump(scores_total, f)\n",
    "    print('Successfully wrote '+str(len(scores_total))+' entries to file: '+ANALYSIS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TOPICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Assignes a numerical value for the *TOPICS* of each *sentence* in each review.**\n",
    "- **Creates a .json file with these values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_reviews=[]\n",
    "for review in reviewlist:\n",
    "    reviews=[]\n",
    "    for sentence in review:\n",
    "        sentences=[]\n",
    "        for word in sentence:\n",
    "            for i,j in word.items():\n",
    "                if i==\"english word\":\n",
    "                    sentences.append(j)\n",
    "            #sentences.append(words)\n",
    "        reviews.append(sentences)\n",
    "    all_reviews.append(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanliness = []\n",
    "for ss in wn.synsets('clean'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        cleanliness.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = []\n",
    "for ss in wn.synsets('service'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        service.append(lemma)\n",
    "for ss in wn.synsets('serve'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        service.append(lemma)\n",
    "for ss in wn.synsets('food'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        service.append(lemma)\n",
    "for ss in wn.synsets('breakfast'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        service.append(lemma)\n",
    "for ss in wn.synsets('lunch'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        service.append(lemma)\n",
    "for ss in wn.synsets('dinner'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        service.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value = []\n",
    "for ss in wn.synsets('value'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        value.append(lemma)\n",
    "for ss in wn.synsets('price'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        value.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = []\n",
    "for ss in wn.synsets('location'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        location.append(lemma)\n",
    "for ss in wn.synsets('transportation'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        location.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sleep = []\n",
    "for ss in wn.synsets('sleep'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        sleep.append(lemma)\n",
    "for ss in wn.synsets('pillow'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        sleep.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "room = []\n",
    "for ss in wn.synsets('room'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        room.append(lemma)\n",
    "for ss in wn.synsets('suite'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        room.append(lemma)\n",
    "for ss in wn.synsets('bedroom'):\n",
    "    for lemma in ss.lemma_names():\n",
    "        room.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_all_reviews = []\n",
    "\n",
    "for review in all_reviews:\n",
    "    topic_review = []\n",
    "    for sentence in review:\n",
    "        topic_sentence = [0]*6\n",
    "        for word in sentence:\n",
    "            if word in cleanliness:\n",
    "                topic_sentence[0] += 1\n",
    "            if word in service:\n",
    "                topic_sentence[1] += 1\n",
    "            if word in value:\n",
    "                topic_sentence[2] += 1\n",
    "            if word in location:\n",
    "                topic_sentence[3] += 1\n",
    "            if word in sleep:\n",
    "                topic_sentence[4] += 1\n",
    "            if word in room:\n",
    "                topic_sentence[5] += 1\n",
    "        topic_review.append(topic_sentence)\n",
    "    topic_all_reviews.append(topic_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics_total = []\n",
    "\n",
    "for review in topic_all_reviews: \n",
    "    for sentence in review:\n",
    "        topics_total.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 18185 entries to file: topics.json\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    json.dump(topics_total, f)\n",
    "    print('Successfully wrote '+str(len(topics_total))+' entries to file: '+OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
